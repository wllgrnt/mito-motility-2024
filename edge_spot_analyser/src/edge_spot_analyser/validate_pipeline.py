"""
Validation script to compare Python pipeline outputs with CellProfiler outputs.

This script compares the CSV files generated by the Python pipeline against
the example CellProfiler outputs to ensure numerical agreement.

Usage:
    python validate_pipeline.py --cp_output example_CP_output/24111_siRNA/ --py_output validation_output/
"""

import argparse
from pathlib import Path

import numpy as np
import pandas as pd


def extract_image_key(filename: str) -> str:
    """Extract a comparable key from image filename."""
    # Extract Well, Seq, XY from filename like:
    # "WellB02_Channel405,561,488,640_Seq0000-MaxIP_XY1_405.tif"
    import re
    match = re.search(r'Well([A-Z]\d+).*Seq(\d+).*XY(\d+)', filename)
    if match:
        return f"{match.group(1)}_{match.group(2)}_{match.group(3)}"
    return filename


def compare_dataframes(
    cp_df: pd.DataFrame,
    py_df: pd.DataFrame,
    name: str,
    tolerance: float = 0.05,
    join_on_image: bool = False
) -> dict:
    """
    Compare two DataFrames for numerical agreement.

    Args:
        cp_df: CellProfiler output DataFrame
        py_df: Python pipeline output DataFrame
        name: Name of the comparison (for logging)
        tolerance: Relative tolerance for numerical comparison (default 5%)
        join_on_image: If True, join on image filename to handle partial datasets

    Returns:
        Dictionary with comparison results
    """
    results = {
        'name': name,
        'cp_rows': len(cp_df),
        'py_rows': len(py_df),
        'discrepancies': []
    }

    # If joining on image, filter to common images
    if join_on_image and 'FileName_Hoechst' in cp_df.columns and 'FileName_Hoechst' in py_df.columns:
        # Create image keys for matching
        cp_df = cp_df.copy()
        py_df = py_df.copy()
        cp_df['_image_key'] = cp_df['FileName_Hoechst'].apply(extract_image_key)
        py_df['_image_key'] = py_df['FileName_Hoechst'].apply(extract_image_key)

        # Find common images
        common_keys = set(cp_df['_image_key']) & set(py_df['_image_key'])
        results['common_images'] = len(common_keys)

        if len(common_keys) == 0:
            results['discrepancies'].append("No common images found between datasets")
            return results

        # Filter to common images
        cp_df = cp_df[cp_df['_image_key'].isin(common_keys)].sort_values('_image_key').reset_index(drop=True)
        py_df = py_df[py_df['_image_key'].isin(common_keys)].sort_values('_image_key').reset_index(drop=True)

        results['matched_rows'] = len(cp_df)

    results['row_count_match'] = len(cp_df) == len(py_df)

    # Check row counts
    if not results['row_count_match']:
        results['discrepancies'].append(
            f"Row count mismatch after filtering: CP={len(cp_df)}, Python={len(py_df)}"
        )
        return results

    # Find common columns (numerical only)
    common_cols = set(cp_df.columns) & set(py_df.columns)
    numerical_cols = [
        col for col in common_cols
        if pd.api.types.is_numeric_dtype(cp_df[col]) and
           pd.api.types.is_numeric_dtype(py_df[col]) and
           not col.startswith('_')
    ]

    results['columns_compared'] = len(numerical_cols)

    # Compare each numerical column
    for col in numerical_cols:
        cp_vals = cp_df[col].values
        py_vals = py_df[col].values

        # Skip if all NaN
        if np.all(np.isnan(cp_vals)) and np.all(np.isnan(py_vals)):
            continue

        # Calculate relative difference
        with np.errstate(divide='ignore', invalid='ignore'):
            rel_diff = np.abs((py_vals - cp_vals) / (np.abs(cp_vals) + 1e-10))

        # Find values exceeding tolerance
        exceeds_tolerance = rel_diff > tolerance

        if np.any(exceeds_tolerance):
            n_exceeds = np.sum(exceeds_tolerance)
            max_diff = np.max(rel_diff[exceeds_tolerance])
            results['discrepancies'].append(
                f"{col}: {n_exceeds}/{len(cp_vals)} values exceed {tolerance*100}% tolerance "
                f"(max diff: {max_diff*100:.2f}%)"
            )

    return results


def validate_pipeline(cp_output_dir: Path, py_output_dir: Path, tolerance: float = 0.05):
    """
    Validate Python pipeline outputs against CellProfiler outputs.

    Args:
        cp_output_dir: Directory containing CellProfiler CSV outputs
        py_output_dir: Directory containing Python pipeline CSV outputs
        tolerance: Relative tolerance for numerical comparison
    """
    print("Comparing outputs:")
    print(f"  CellProfiler: {cp_output_dir}")
    print(f"  Python:       {py_output_dir}")
    print(f"  Tolerance:    {tolerance*100}%\n")

    # Build image number mapping - CP Nuclei.csv has filenames, Python Image.csv has them
    cp_nuclei = pd.read_csv(cp_output_dir / 'Nuclei.csv')
    py_image = pd.read_csv(py_output_dir / 'Image.csv')

    # Get unique image keys from CP Nuclei.csv
    cp_image_info = cp_nuclei[['ImageNumber', 'FileName_Hoechst']].drop_duplicates()
    cp_image_info['_image_key'] = cp_image_info['FileName_Hoechst'].apply(extract_image_key)

    py_image['_image_key'] = py_image['FileName_Hoechst'].apply(extract_image_key)

    # Find common images
    common_keys = set(cp_image_info['_image_key']) & set(py_image['_image_key'])
    print(f"  Common images: {len(common_keys)} (CP has {len(cp_image_info)}, Python has {len(py_image)})\n")

    # Build mapping from CP ImageNumber to Python ImageNumber via image_key
    cp_key_to_num = dict(zip(cp_image_info['_image_key'], cp_image_info['ImageNumber'], strict=True))
    py_key_to_num = dict(zip(py_image['_image_key'], py_image['ImageNumber'], strict=True))
    cp_to_py_image = {cp_key_to_num[k]: py_key_to_num[k] for k in common_keys}

    # Files to compare (skip Image.csv since CP version lacks filename columns)
    files = ['Nuclei.csv', 'Expand_Nuclei.csv', 'Perinuclear_region.csv']

    all_results = []

    for filename in files:
        cp_file = cp_output_dir / filename
        py_file = py_output_dir / filename

        if not cp_file.exists():
            print(f"⚠️  {filename}: CellProfiler file not found, skipping")
            continue

        if not py_file.exists():
            print(f"❌ {filename}: Python output not found")
            continue

        # Load DataFrames
        cp_df = pd.read_csv(cp_file)
        py_df = pd.read_csv(py_file)

        if False:  # Image.csv comparison disabled
            results = compare_dataframes(cp_df, py_df, filename, tolerance, join_on_image=True)
        else:
            # For object-level CSVs, filter to common images and compare
            # Filter CP to only images in common
            cp_df = cp_df[cp_df['ImageNumber'].isin(cp_to_py_image.keys())].copy()

            # Map CP ImageNumber to Python ImageNumber for matching
            cp_df['_py_image'] = cp_df['ImageNumber'].map(cp_to_py_image)

            # Filter Python to only images in common
            py_images_in_common = set(cp_to_py_image.values())
            py_df = py_df[py_df['ImageNumber'].isin(py_images_in_common)].copy()

            # Sort both by (mapped image, object) for alignment
            cp_df = cp_df.sort_values(['_py_image', 'ObjectNumber']).reset_index(drop=True)
            py_df = py_df.sort_values(['ImageNumber', 'ObjectNumber']).reset_index(drop=True)

            results = {
                'name': filename,
                'cp_rows': len(cp_df),
                'py_rows': len(py_df),
                'row_count_match': len(cp_df) == len(py_df),
                'discrepancies': []
            }

            if not results['row_count_match']:
                results['discrepancies'].append(
                    f"Row count mismatch in common images: CP={len(cp_df)}, Python={len(py_df)}"
                )
            else:
                # Find common numerical columns
                common_cols = set(cp_df.columns) & set(py_df.columns)
                numerical_cols = [
                    col for col in common_cols
                    if pd.api.types.is_numeric_dtype(cp_df[col]) and
                       pd.api.types.is_numeric_dtype(py_df[col]) and
                       not col.startswith('_') and col not in ['ImageNumber', 'ObjectNumber']
                ]
                results['columns_compared'] = len(numerical_cols)

                for col in numerical_cols:
                    cp_vals = cp_df[col].values
                    py_vals = py_df[col].values

                    if np.all(np.isnan(cp_vals)) and np.all(np.isnan(py_vals)):
                        continue

                    with np.errstate(divide='ignore', invalid='ignore'):
                        rel_diff = np.abs((py_vals - cp_vals) / (np.abs(cp_vals) + 1e-10))

                    exceeds_tolerance = rel_diff > tolerance
                    if np.any(exceeds_tolerance):
                        n_exceeds = np.sum(exceeds_tolerance)
                        max_diff = np.max(rel_diff[exceeds_tolerance])
                        results['discrepancies'].append(
                            f"{col}: {n_exceeds}/{len(cp_vals)} values exceed {tolerance*100}% tolerance "
                            f"(max diff: {max_diff*100:.2f}%)"
                        )

        all_results.append(results)

        # Print results
        if results['discrepancies']:
            print(f"❌ {filename}:")
            print(f"   Rows: CP={results['cp_rows']}, Python={results['py_rows']}")
            print(f"   Columns compared: {results.get('columns_compared', 0)}")
            for disc in results['discrepancies']:
                print(f"   - {disc}")
        else:
            print(f"✅ {filename}: All measurements agree within {tolerance*100}% tolerance")
            print(f"   Rows matched: {results.get('matched_rows', results['py_rows'])}, Columns compared: {results.get('columns_compared', 0)}")

        print()

    # Summary
    n_passed = sum(1 for r in all_results if not r['discrepancies'])
    n_total = len(all_results)

    print("=" * 60)
    print(f"Summary: {n_passed}/{n_total} files passed validation")
    print("=" * 60)

    if n_passed == n_total:
        print("✅ All files validated successfully!")
        return 0
    else:
        print("❌ Some files have discrepancies")
        return 1


def main():
    parser = argparse.ArgumentParser(
        description='Validate Python pipeline outputs against CellProfiler'
    )

    parser.add_argument(
        '--cp_output',
        type=Path,
        required=True,
        help='Directory with CellProfiler CSV outputs'
    )

    parser.add_argument(
        '--py_output',
        type=Path,
        required=True,
        help='Directory with Python pipeline CSV outputs'
    )

    parser.add_argument(
        '--tolerance',
        type=float,
        default=0.05,
        help='Relative tolerance for numerical comparison (default 0.05 = 5%%)'
    )

    args = parser.parse_args()

    exit_code = validate_pipeline(args.cp_output, args.py_output, args.tolerance)
    exit(exit_code)


if __name__ == '__main__':
    main()
